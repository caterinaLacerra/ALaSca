---
layout: post
title:  "An Automated Approach for Large-Scale Lexical Substitution"
---
This website contains the dataset described in [ALaSca](). The code to reproduce the experiments is available on [GitHub]().

## Abstract
The lexical substitution task aims at finding suitable replacements for words in context. It has proved to be useful in several areas, such as word sense induction and text simplification, as well as in more practical applications such as writing-assistant tools. However, the paucity of annotated data has forced researchers to apply mainly unsupervised approaches, limiting the applicability of large pre-trained models and thus hampering the potential benefits of supervised approaches to the task. In this paper, we mitigate this issue by proposing ALaSca, a novel approach to automatically creating large-scale datasets for English lexical substitution. ALaSca allows examples to be produced for potentially any word in a language vocabulary and to cover most of the meanings it lists. Thanks to this, we can unleash the full potential of neural architectures and finetune them on the lexical substitution task. Indeed, when using our data, a transformer-based model  performs substantially better than when using manually-annotated data only.   
## ALaSca Dataset

## Supplementary Material
In the [supplementary material](/assets/supplementary_alasca.pdf) we provide the results for each tuned value for the similarity threshold.


## Reference

## Authors

### Acknowledgements
The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE No. 726487 under the European Union’s Horizon 2020 research and innovation programme.

This work was supported in part by the MIUR under grant “Dipartimenti di eccellenza 2018-2022” of the Department of Computer Science of the Sapienza University of Rome.

### License
